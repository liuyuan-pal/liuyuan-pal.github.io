
<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Yuan Liu - Homepage</title>
      <link rel="stylesheet" href="./css/main.css">
      <script src="./css/jquery-1.10.2.js.download"></script>

		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-TP2ZLLPT0R"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-TP2ZLLPT0R');
		</script>
   </head>

   <!-- Tab links -->
   <body style="" data-new-gr-c-s-check-loaded="14.977.0">
      <header>
         <div id="header">
            <div class="tab">
               <!-- <div class="tab-name"><a style="text-decoration: none;" href="#">Cheng Lin</a></div> -->
               <div class="tab-link"><a style="text-decoration: none;" href="https://github.com/IGL-HKUST">Lab</a></div>
               <div class="tab-link"><a style="text-decoration: none;" href="#services">Services</a></div>
               <div class="tab-link"><a style="text-decoration: none;" href="#publications">Publications</a></div>
               <div class="tab-link"><a style="text-decoration: none;" href="#news">Openings</a></div>
               <!-- <div class="tab-link"><a style="text-decoration: none;" href="#">Home</a></div> -->
            </div>
         </div>
         <script>
            $("#header").load("./header.html");
         </script>
      </header>
      
	  
	  <div class="content top_block">
         <table class="about-table">
            <tbody>
               <tr>
                  <br>
                  <td class="image-column">
                     <img src="./images/selfie-high-quality.jpg" alt="Photo" width="250" >
                  </td>
                  <td class="description-column">
                     <div class="content text">
                        <h3>Yuan Liu (刘缘)</h3>
						      <h4>Assistant Professor@HKUST, PostDoc@NTU, PhD@HKU </h4>
                        <p>yuanly@ust.hk</p>
                  <!-- <p style="text-align: justify"> -->
                  <p>
                     I'm an assistant professor at <a href="https://isd.hkust.edu.hk/">ISD HKUST</a>, leading the <a href="https://github.com/IGL-HKUST">Intelligent Graphics Lab</a>.
                     Prior to that, I worked in Nanyang Technological University (NTU) as a PostDoc researcher under the supervision of Prof. <a href="https://liuziwei7.github.io/">Ziwei Liu</a>. 
                     I obtained my PhD degree at the University of Hong Kong (HKU) under the supervision of Prof. <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a> and Prof. <a href="https://homepages.inf.ed.ac.uk/tkomura/">Taku Komura</a>. 
					 Previously, I also worked with Prof. <a href="https://xzhou.me/"> Xiaowei Zhou</a> at Zhejiang Univeristy (ZJU) in 2019. 
					 I got my master's and bachelor's degree at Wuhan University (WHU) under the supervision of Prof. <a href=>Bisheng Yang</a> in 2015 and 2018 respectively.
                     I'm one of the organizers of <a href="https://anysyn3d.github.io/about.html">AnySyn3D</a>. 
                     My research mainly concentrates on 3D vision and graphics. 
                     I currently work on topics including neural 3D reconstruction, 3D generative models, and 3D-aware video generation.
                  </p>
                  
                  <!-- In 2018-2019, I worked in CAD&amp;CG lab of Zhejiang University advised by Prof. <a href="https://xzhou.me/">Xiaowei Zhou</a>.  -->
                  <!-- I received my master degree at LIESMARS of Wuhan University advised by Prof. <a href="http://www.lmars.whu.edu.cn/enbisheng-yang/">Bisheng Yang</a>.  -->
                  <!-- My research interest includes computer graphics and 3D computer vision. I currently work on topics about 3D AIGC including neural rendering/representations and diffusion generative models.  -->
                  <!-- <p style="color:red; font-weight:bold;">I'll graduate before Jul. 2024 and I'm looking for a research position on CG and 3D CV (Diffusion/NeRF/NeuS/GS)!</p> -->
                        <p>
                        </p>
						<!-- <p class = "news"> -->
						
						<!-- </p> -->
						
						
						<!-- <a target=_blank href="https://github.com/liuyuan-pal" target="_blank">[Github]</a> &nbsp
						<a target=_blank href="https://twitter.com/YuanLiu41955461" target="_blank">[Twitter]</a> &nbsp
						<a target=_blank href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ" target="_blank">[Google Scholar]</a> -->
                  </div>

               <div class="social-links-with-text">
                   <div class="social-item">
                      <a target=_blank href="https://github.com/liuyuan-pal" target="_blank" class="social-icon">
                         <img src="./images/github.png" alt="GitHub" width="20" height="20">
                      </a>
                      <a target=_blank href="https://github.com/liuyuan-pal" target="_blank" class="social-text">GitHub</a>
                   </div>
                   <div class="social-item">
                      <a target=_blank href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ" target="_blank" class="social-icon">
                         <img src="./images/google-scholar.png" alt="Google Scholar" width="20" height="20">
                      </a>
                      <a target=_blank href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ" target="_blank" class="social-text">Google Scholar</a>
                   </div>
                   <div class="social-item">
                      <a target=_blank href="https://twitter.com/YuanLiu41955461" target="_blank" class="social-icon">
                         <img src="./images/twitter.svg" alt="Twitter" width="20" height="20">
                      </a>
                      <a target=_blank href="https://twitter.com/YuanLiu41955461" target="_blank" class="social-text">Twitter</a>
                   </div>
               </div>
               
               <br>

                  </td>
               </tr>
            </tbody>
         </table>
      </div>


      	  <!-- <div class="content profile-section">
         <div class="profile-header">
            <div class="profile-image">
               <img src="./images/selfie-high-quality.jpg" alt="Photo" width="220">
            </div>
            <div class="profile-info">
               <h3>Yuan Liu (刘缘)</h3>
               <p>Assistant Professor</p>
               <p>Division of Integrative System and Design (ISD)</p>
               <p>Academy of Interdisciplinary Studies (AIS)</p>
               <p>Hong Kong University of Science and Technology (HKUST)</p>
               <p>✉yuanly@ust.hk</p>
               
               <div class="social-links-with-text">
                   <div class="social-item">
                      <a target=_blank href="https://github.com/liuyuan-pal" target="_blank" class="social-icon">
                         <img src="./images/github.png" alt="GitHub" width="20" height="20">
                      </a>
                      <a target=_blank href="https://github.com/liuyuan-pal" target="_blank" class="social-text">GitHub</a>
                   </div>
                   <div class="social-item">
                      <a target=_blank href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ" target="_blank" class="social-icon">
                         <img src="./images/google-scholar.png" alt="Google Scholar" width="20" height="20">
                      </a>
                      <a target=_blank href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ" target="_blank" class="social-text">Google Scholar</a>
                   </div>
                   <div class="social-item">
                      <a target=_blank href="https://twitter.com/YuanLiu41955461" target="_blank" class="social-icon">
                         <img src="./images/twitter.svg" alt="Twitter" width="20" height="20">
                      </a>
                      <a target=_blank href="https://twitter.com/YuanLiu41955461" target="_blank" class="social-text">Twitter</a>
                   </div>
               </div>
            </div>
         </div> -->
         
         <!-- <div class="profile-bio">
            <p class="bio">I am an Assistant Professor at the Department of Computer Science and Engineering at Macau University of Science and Technology (MUST). 
            
            I received my Ph.D. in Computer Science from The Univeristy of Hong Kong (HKU), advised by Prof. <a target=_blank href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a>. 
            I visited Visual Computing Group at Technical University of Munich (TUM), advised by Prof. <a target=_blank href="https://niessnerlab.org/index.html">Matthias Nießner</a>.
            Before that, I completed my B.Eng. degree at Shandong University working on geometry and graphics. My research interests include Computer Graphics, 3D Vision, 3D AIGC, Geometric Modeling, and Human Computer Interaction. 
            
            <br>
            Prior to joining MUST, I was a Lead Researcher of Graphics AI direction at miHoYo, and a Senior Researcher at Tencent IEG. I was selected for Tencent's Top Talent Program for Technology Elites.
            
            I am an organizer and co-founder member of <a target=_blank href="https://anysyn3d.github.io/">AnySyn3D</a>, a non-profit research interest group comprising individuals with a strong interest in exploring research problems and cutting-edge technologies in 3D AIGC.
            </p>
         </div>
      </div> -->

	  
      <div class="content">
         <a name="news"></a>
         <h3>Openings <a href="https://www.xiaohongshu.com/explore/69567ade0000000021032bdb?source=webshare&xhsshare=pc_web&xsec_token=AB_cwNeh9IJcW19P-0ax0mqirhWjqtGJUzQV_TDVVGsGs=&xsec_source=pc_share">[Chinese Version]</a></h3>
         <hr>
         <p>
         <b style="color:red"> 
            We are constantly recruiting passionate PhD and visiting students to join our research team! 
            We especially welcome international students with a strong drive and a solid background in related fields. 
            <!-- If you’re eager to make an impact in cutting-edge research, we’d love to have you on board! -->
         </b>
          <!-- <b style="color:red">Currently, There are no positions for PhD students (2025 fall) and RA, but there are still openings for visiting students. </b> -->
         </p>

         <p>
         We are currently working on the following topics.
         </p>
         <ol>
            <li>Neural 3D reconstruction (like <a href="https://igl-hkust.github.io/Align3R.github.io/">Align3R</a>, <a href="https://igl-hkust.github.io/TrackingWorld.github.io/">TrackingWorld</a>,
               <a href="https://maddog241.github.io/mvinverse-page/">MVInverse</a>, <a href="https://murphylmf.github.io/UniSH/">UniSH</a>).</li>
            <li>3D asset generation (like <a href="https://xishuxishu.github.io/SyncHuman.github.io/">SyncHuman</a>, <a href="https://xrvitd.github.io/MeshMosaic/index.html">MeshMosaic</a>, <a href="https://czvvd.github.io/PartSAMPage/">PartSAM</a>).</li>
            <li>3D-aware video generation (like <a href="https://igl-hkust.github.io/das/">Diffusion as Shader</a>, <a href="">CoMoVi</a>) .</li>
			   <li>3D LLM agents (like <a href="https://openreview.net/forum?id=7nOl5W6xU4">CityAnchor</a>, <a href="https://github.com/WHU-USI3DV/SpatialLLM">SpatialLLM</a>).</li>
         </ol>
         <p >
         Some recent works can be found in the <a href="#publications">Publications</a> section.
         If you are interested in working with me on these topics, please fill the Google form 
         <a href="https://docs.google.com/forms/d/e/1FAIpQLSehvKvgl7eJc8n8qonDb5tBwkMd4h5zQYIDKxmsD5X-IiybTQ/viewform?usp=sf_link">here</a> 
         and drop an email to <a href="mailto:yuanly@ust.hk">yuanly@ust.hk</a>. I will contact you within 2 weeks if the backgrounds are matched.
         </p>

         <p>
            We offer a competitive monthly stipend of 19,700 HKD (around 2,500 USD) to support your academic journey. Exceptional candidates are also encouraged to apply for the prestigious <a href="https://fytgs.hkust.edu.hk/scholarships/hong-kong-phd-fellowship-scheme">HKPFS</a>, which provides an enhanced stipend of 28,000 HKD (approximately 3,600 USD).
         </p>
         <br><br>
      </div>
         
      <div class="content">
         <a name="publications"></a>
         <h3>Selected Publications (<a href="https://scholar.google.com/citations?user=yRAHVcgAAAAJ">Google Scholar</a>)</h3>
		   <hr>
         <!-- <p> Full publication list can be found <a href="full-pub.html">here</a>.</p> -->
        <b>*Equal contribution †Corresponding author</b>
         <table class="publication-table">
         
         <tr>
            <td class="image-column">
               <!-- <div class="demo-video"> -->
                  <img src="./images/tracking-world.gif" width=100% height=100% class="publication-image">
               <!-- </div> -->
            </td>
            <td class="description-column">
                  <div class="paper_title">TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels</div>
                  <div class="paper_authors">
                     Jiahao Lu, Weitao Xiong, Jiacheng Deng, Peng Li, Tianyu Huang, Zhiyang Dou, Cheng Lin, Sai-Kit Yeung, <b>Yuan Liu</b>
                  </div>
                  <div class="paper_venue"> <b>NeurIPS 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2512.08358">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://igl-hkust.github.io/TrackingWorld.github.io/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/IGL-HKUST/TrackingWorld">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <!-- <div class="demo-video"> -->
                  <img src="./images/synchuman.gif" width=100% height=100% class="publication-image">
               <!-- </div> -->
            </td>
            <td class="description-column">
                  <div class="paper_title">SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction</div>
                  <div class="paper_authors">
                     Wenyue Chen, Peng Li†, Wangguandong Zheng, Chengfeng Zhao, Mengfei Li, Yaolong Zhu, Zhiyang Dou, Ronggang Wang, <b>Yuan Liu†</b>
                  </div>
                  <div class="paper_venue"> <b>NeurIPS 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2510.07723">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://xishuxishu.github.io/SyncHuman.github.io/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/IGL-HKUST/SyncHuman">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video">
                  <video width=100% height=100% muted autoplay loop>
                     <source src="images/DaS.mp4" type="video/mp4">
                     </video>
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control</div>
                  <div class="paper_authors">
                     Zekai Gu, Rui Yan, Jiahao Lu, Peng Li, Zhiyang Dou, Chenyang Si, Zhen Dong, Qifeng Liu, Cheng Lin, Ziwei Liu, Wenping Wang, <b>Yuan Liu</b>
                  </div>
                  <div class="paper_venue"> <b>SIGGRAPH 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2501.03847">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://igl-hkust.github.io/das/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/IGL-HKUST/DiffusionAsShader">[Code]</a></span>
            </div>
            </td>
            </tr>
         
         <tr>
            <td class="image-column">
               <div class="demo-video">
                  <video width=100% height=100% muted autoplay loop>
                     <source src="images/align3r.mp4" type="video/mp4">
                     </video>
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Align3R: Aligned Monocular Depth Estimation for Dynamic Videos</div>
                  <div class="paper_authors">
                     Jiahao Lu*, Tianyu Huang*, Peng Li, Zhiyang Dou, Cheng Lin, Zhiming Cui, Zhen Dong, Sai-Kit Yeung, Wenping Wang, <b>Yuan Liu</b>
                  </div>
                  <div class="paper_venue"> <b>CVPR 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2412.03079">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://igl-hkust.github.io/Align3R.github.io/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/jiah-cloud/Align3R">[Code]</a></span>
            </div>
            </td>
            </tr>
         
         <tr>
            <td class="image-column">
               <div class="demo-video">
                  <video width=100% height=100% muted autoplay loop>
                     <source src="images/PSHuman.mp4" type="video/mp4">
                     </video>
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">PSHuman: Photorealistic Single-image 3D Human Reconstruction using Cross-Scale Multiview Diffusion and Explicit Remeshing</div>
                  <div class="paper_authors">
                     Peng Li, Wangguandong Zheng, <b>Yuan Liu</b>†, Tao Yu, Yangguang Li, Xingqun Qi, Mengfei Li, Xiaowei Chi, Siyu Xia, Wei Xue, Wenhan Luo†, Qifeng Liu, Yike Guo
                  </div>
                  <div class="paper_venue"> <b>CVPR 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2501.03847">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://igl-hkust.github.io/das/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/IGL-HKUST/DiffusionAsShader">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video">
                  <video width=100% height=100% muted autoplay loop>
                     <source src="images/vistadream.mp4" type="video/mp4">
                     </video>
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">VistaDream: Sampling multiview consistent images for single-view scene reconstruction</div>
                  <div class="paper_authors">
                     Haiping Wang, <b>Yuan Liu</b>†, Ziwei Liu, Wenping Wang, Zhen Dong†, Bisheng Yang
                  </div>
                  <div class="paper_venue"> <b>ICCV 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2410.16892">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://vistadream-project-page.github.io/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/WHU-USI3DV/VistaDream">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
               <source src="images/era3d-lr.mp4" type="video/mp4">
               </video></div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Era3D: High-Resolution Multiview Diffusion using Efficient Row-wise Attention</div>
                  <div class="paper_authors">
                        Peng Li*, <b>Yuan Liu*</b>, Xiaoxiao Long†, Feihu Zhang, Cheng Lin, Mengfei Li, Xingqun Qi, Shanghang Zhang, Wei Xue, Wenhan Luo, Ping Tan, Wenping Wang, Qifeng Liu, Yike Guo†
                  </div>
                  <div class="paper_venue"> <b>NeurIPS 2024</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2405.11616">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://penghtyx.github.io/Era3D/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/pengHTYX/Era3D">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
               <source src="images/syncdreamer-lr.mp4" type="video/mp4">
               </video></div>
            </td>
            <td class="description-column">
                  <div class="paper_title">SyncDreamer: Generating Multiview-consistent Images from a Single-view Image</div>
                  <div class="paper_authors">
                     <b>Yuan Liu*</b>, Cheng Lin*, Zijiao Zeng, Xiaoxiao Long†, Lingjie Liu, Taku Komura, Wenping Wang†
                  </div>
                  <div class="paper_venue"> <b>ICLR 2024 (Spotlight)</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2309.03453">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://liuyuan-pal.github.io/SyncDreamer/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/liuyuan-pal/SyncDreamer">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
               <source src="images/wonder3d-lr.mp4" type="video/mp4">
               </video></div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Wonder3D: Single Image to 3D using Cross-Domain Diffusion</div>
                  <div class="paper_authors">
                  Xiaoxiao Long*, Yuan-Chen Guo*, Cheng Lin†, <b>Yuan Liu</b>, Zhiyang Dou, Lingjie Liu, Yuexin Ma, Song-Hai Zhang, Marc Habermann, Christian Theobalt, Wenping Wang†
                  </div>
                  <div class="paper_venue"> <b>CVPR 2024 (Highlight)</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/pdf/2310.15008.pdf">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://www.xxlong.site/Wonder3D/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/xxlong0/Wonder3D">[Code]</a></span>
            </div>
            </td>
            </tr>

         <tr>
            <td class="image-column">
               <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
               <source src="images/nero-lr.mp4" type="video/mp4">
               </video></div>
            </td>
            <td class="description-column">
                  <div class="paper_title">NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from Multiview Images</div>
                  <div class="paper_authors">
                  <b>Yuan Liu</b></a>, Peng Wang, Cheng Lin, Xiaoxiao Long, Jiepeng Wang, Lingjie Liu, Taku Komura, Wenping Wang
                  </div>
                  <div class="paper_venue"> <b>SIGGRAPH 2023 (ToG)</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2305.17398">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://liuyuan-pal.github.io/NeRO/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/liuyuan-pal/NeRO">[Code]</a></span>
            </div>
            </td>
            </tr>
         
         <tr>
            <td class="image-column">
               <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
               <source src="images/f2nerf-lr.mp4" type="video/mp4">
               </video></div>
            </td>
            <td class="description-column">
                  <div class="paper_title">F<sup>2</sup>NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories</div>
                  <div class="paper_authors">
                  Peng Wang*, <b>Yuan Liu*</b>, Zhaoxi Chen, Ziwei Liu, Lingjie Liu, Taku Komura, Christian Theobalt, Wenping Wang
                  </div>
                  <div class="paper_venue"> <b>CVPR 2023 (Highlight)</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2303.15951">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://totoro97.github.io/projects/f2-nerf/">[Project Page]</a></span>
               <span class="link"><a target=_blank href="https://github.com/Totoro97/f2-nerf">[Code]</a></span>
            </div>
            </td>
            </tr>			
			
			<tr>
               <td class="image-column">
				  <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
					<source src="images/neuray-lr.mp4" type="video/mp4">
				  </video></div>
               </td>
               <td class="description-column">
                  <div class="paper_title">Neural Rays for Occlusion-aware Image-based Rendering</div>
                  <div class="paper_authors">
                     <b>Yuan Liu</b>, Sida Peng, Lingjie Liu, Qianqian Wang, Peng Wang, Christian Theobalt, Xiaowei Zhou, Wenping Wang		  
                  </div>
                  <div class="paper_venue"> <b>CVPR 2022</b> </div>
				  <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2107.13421">[Paper]</a></span>
				  <span class="link"><a target=_blank href="https://liuyuan-pal.github.io/NeuRay/">[Project Page]</a></span>
                  <span class="link"><a target=_blank href="https://github.com/liuyuan-pal/NeuRay">[Code]</a></span>

				  </div>
               </td>
            </tr>
			
			
			<tr>
               <td class="image-column">
				  <div class="demo-video"> <video width=100% height=100% muted autoplay loop>
					<source src="images/neus.mp4" type="video/mp4">
				  </video></div>
               </td>
               <td class="description-column">
                  <div class="paper_title">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</div>
                  <div class="paper_authors">
                     Peng Wang, Lingjie Liu, <b>Yuan Liu</b>, Christian Theobalt, Taku Komura, Wenping Wang		  
                  </div>
                  <div class="paper_venue"> <b>NeurIPS 2021 (Spotlight)</b> </div>
				  <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2106.10689">[Paper]</a></span>
				  <span class="link"><a target=_blank href="https://lingjie0206.github.io/papers/NeuS/">[Project Page]</a></span>
                  <span class="link"><a target=_blank href="https://github.com/Totoro97/NeuS">[Code]</a></span>

				  </div>
               </td>
            </tr>
			
         </table>



         <!-- <a name="mentor"></a>
         <h3>Mentoring</h3>
         <hr>
         I spent wonderful time working with talented master or junior PhD students on some interesting research projects as follows.
         
   
         <ul>
            <li>
            <a href="https://hpwang-whu.github.io/">Haiping Wang</a>: 
            <strong>YOHO</strong> (<a href="https://hpwang-whu.github.io/YOHO/">MM'22</a>), 
            <strong>RoReg</strong> (<a href="https://hpwang-whu.github.io/RoReg/">TPAMI'23</a>)
            <strong>SGHR</strong> (<a href="https://github.com/WHU-USI3DV/SGHR">CVPR'23</a>)
            <strong>FreeReg</strong> (<a href="https://whu-usi3dv.github.io/FreeReg/">ICLR'23</a>)
            </li>
            <ul>
               <li>PhD at WHU.</li>
            </ul>
            <li>
            <a href="https://runsong123.github.io/">Runsong Zhu</a>: 
            <strong>AdaFit</strong> (<a href="https://runsong123.github.io/AdaFit/">ICCV'21</a>)
            </li>
            <ul><li>Master at WHU, Ph.D. at CUHK</li></ul>
            <li>
            <a href="https://zzzyuqing.github.io/">Yuqing Zhang</a>: 
            <strong>DreamMat</strong> (<a href="https://zzzyuqing.github.io/dreammat.github.io/">SIGGRAPH'24</a>)
            </li>
            <ul><li>Master at ZJU</li></ul>
            <li>
               <a href="https://shanemankiw.github.io/">Jionghao Wang</a>:
               <strong>SO-SMPL</strong> (<a href="https://shanemankiw.github.io/SO-SMPL/">ECCV'24</a>)
               <ul><li>Master at SJTU, PhD at TAMU</li></ul>
            </li>
            <li>
            <a href="https://scholar.google.com/citations?user=8eTLCkwAAAAJ&hl=zh-CN">Peng Li</a>: 
            <strong>Era3D</strong> (<a href="https://penghtyx.github.io/Era3D/">NeurIPS'24</a>),
            <strong>PSHuman</strong> (<a href="https://penghtyx.github.io/PSHuman/">CVPR'25</a>),
            <strong>CMD</strong> (<a href="https://arxiv.org/abs/2505.07003/">SIGGRAPH'25</a>)
            <ul><li>PhD at HKUST</li></ul>
            </li>
            <li>
            <a href="https://github.com/Asparagus15">Wenqi Jiangying</a>: 
            <strong>GaussianShader</strong> (<a href="https://asparagus15.github.io/GaussianShader.github.io/">CVPR'24</a>)
            <ul><li>PhD at ShanghaiTech University</li></ul>
            </li>
            <li>
            <a href="https://github.com/liuar0512">Anran Liu</a>: 
            <strong>NeRFBuff</strong> (<a href="https://ieeexplore.ieee.org/abstract/document/10508469/">TVCG'24</a>),
            <strong>Part123</strong> (<a href="https://liuar0512.github.io/part123_official_page/">SIGGRAPH'24</a>)
            <ul><li>PhD at HKU</li></ul>
            </li>
   
         </ul>
		 --!>

      </div>
	  
      <!-- End of the publication -->

      <!-- <div class="content"> -->
		 <!-- <a name="experiences"></a> -->
         <!-- <h3>Experiences</h3> -->
		  <!-- <hr> -->
         <!-- <table class="publication-table"> -->
               <!-- <td class="general-item-left"> -->
                  <!-- <h5></h5> -->
               <!-- </td> -->
			   
               <!-- <td class="general-item-right"> -->
				 <!-- <div class="content text"><li><a class="affliation", target=_blank href="https://niessnerlab.org/index.html">Visual Computing Group</a>,  -->
				 <!-- Technical University of Munich (TUM) <br> -->
				 <!-- <b>Research Visit</b> <br> -->
				 <!-- Advisor: <a  target=_blank href="https://niessnerlab.org/index.html">Prof. Matthias Nießner</a> <br> -->
				 <!-- May 2019 - Oct 2019 -->
				 <!-- </div> -->
				 <!-- <br> -->
				 
				 <!-- <div class="content text"><li> <a class="affliation", target=_blank href="http://ercdm.sdu.edu.cn/">Research Center of Digital Media Technology</a>, Ministry of Education <br>  -->
				 <!-- <b>Research Assistant</b> <br> -->
				 <!-- Advisor: <a  target=_blank href="https://www.sc.sdu.edu.cn/info/1045/1738.htm">Prof. Chenglei Yang</a> <br>  -->
				 <!-- Dec 2014 - June 2016 -->
				 <!-- </div> -->
               <!-- </td> -->
         <!-- </table> -->
      <!-- </div> -->


		
			<div class="content">
		<a name="services"></a>
         <h3>Services</h3>
		  <hr>
         <table class="publication-table">
               <td class="general-item-left">
                  <h5></h5>
               </td>
			   
               <td class="general-item-right">
				 
				 <li> <b>Associate Editor</b>: <br>
				 IEEE TVCG
               <br><br>

				 <li> <b>Area Chair</b>: <br>
				 3DV 2026
               <br><br>
				 
				 <li> <b>Program Committee Member</b>: <br>
				 SIGGRAPH Asia 2026
               <br><br>

				 
             <li> <b>Co-Founder and Organizer</b>: <br>
				 AnySyn3D Research Community (Currently affiliated with the CSIG Technical Committee on Intelligent Graphics Computing)

               </td>
         </table>
      </div>

	
	<div class="content">
	<br>
	<br>
			<hr>
			<div align="center">
				<b>&copy;Yuan Liu.</b>&nbsp Last updated: 15 Feb, 2026.
			</div>
			<br>
	<br>
	</div>


   </body>
</html>
